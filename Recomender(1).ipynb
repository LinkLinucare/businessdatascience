{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Her bruger vi picke til at få den trænede data, og åbner det. Jeg har uploadet det i dokumentet\n",
        "\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "with open('kmeans_model.pkl', 'rb') as file:\n",
        "    kmeans_model = pickle.load(file)\n",
        "\n",
        "with open('logistic_regression_model.pkl', 'rb') as file:\n",
        "    logistic_regression_model = pickle.load(file)\n",
        "\n",
        "af_usa_loaded = pd.read_csv('af_usa_processed.csv')"
      ],
      "metadata": {
        "id": "qaxUrLjneRsz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "import re\n",
        "import string"
      ],
      "metadata": {
        "id": "-n4XxQNIrO8V"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "af_usa_loaded = pd.read_csv('/content/af_usa_processed.csv')\n",
        "\n",
        "# Definer funktionen til at forbehandle tekst\n",
        "def preprocess_text(text):\n",
        "    if isinstance(text, str):\n",
        "        # Converter til små bogstaver\n",
        "        text = text.lower()\n",
        "        # Fjern tegnsætning\n",
        "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "        # Fjern tal\n",
        "        text = re.sub(r'\\d+', '', text)\n",
        "        # Fjern ekstra mellemrum\n",
        "        text = ' '.join(text.split())\n",
        "    else:\n",
        "        # Hvis der ikke er tekst i stringen\n",
        "        text = ''\n",
        "    return text"
      ],
      "metadata": {
        "id": "HFoUIdi9rRSY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sikr at kolonnen 'use_cleaned' eksisterer\n",
        "if 'use_cleaned' not in af_usa_loaded.columns:\n",
        "    # Antager at kolonnen 'use' eksisterer og skal rengøre\n",
        "    af_usa_loaded['use_cleaned'] = af_usa_loaded['use'].apply(preprocess_text)\n",
        "\n",
        "# Brug TfidfVectorizer til at konvertere tekstdata til funktione\n",
        "vectorizer = TfidfVectorizer(max_features=50)\n",
        "\n",
        "# Remove or replace np.nan values in 'use_cleaned' column\n",
        "af_usa_loaded['use_cleaned'] = af_usa_loaded['use_cleaned'].fillna('')\n",
        "\n",
        "tfidf_matrix = vectorizer.fit_transform(af_usa_loaded['use_cleaned'])\n",
        "\n",
        "# Opret en ny kolonne der angiver, om lån har høj sandsynlighed (1) eller lav sandsynlighed (0)\n",
        "af_usa_loaded['high_chance'] = np.where(af_usa_loaded['lender_count'] >= af_usa_loaded['lender_count'].median(), 1, 0)"
      ],
      "metadata": {
        "id": "UVYCTufEqFNH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definer funktionerne og målene til den superviserede model\n",
        "X_supervised = pd.DataFrame(tfidf_matrix.toarray())\n",
        "y_supervised = af_usa_loaded['high_chance']\n",
        "\n",
        "# Split data i trænings- og testdata\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_supervised, y_supervised, test_size=0.2, random_state=42)\n",
        "\n",
        "# Vi bruger logistisk regression model\n",
        "classifier = LogisticRegression(random_state=42)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Funktion til at anbefale baseret på nøgleord\n",
        "def recommend_chance_supervised(use_description):\n",
        "    use_description_cleaned = preprocess_text(use_description)\n",
        "    input_tfidf = vectorizer.transform([use_description_cleaned]).toarray()\n",
        "    predicted_chance = classifier.predict(input_tfidf)[0]\n",
        "    return \"High Chance\" if predicted_chance == 1 else \"Low Chance\""
      ],
      "metadata": {
        "id": "LKH3JmqPrVgB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommender based on K-Means clustering\n",
        "def find_similar_loans(loan_input):\n",
        "    # Definer og tilpas scaler\n",
        "    scaler = StandardScaler()\n",
        "    scaled_features = scaler.fit_transform(af_usa_loaded[['loan_amount', 'term_in_months', 'lender_count']])\n",
        "\n",
        "    # Definer og tilpas PCA\n",
        "    pca = PCA(n_components=2)\n",
        "    pca_features = pca.fit_transform(scaled_features)\n",
        "\n",
        "    # Find nærmeste klynge baseret på inputdata\n",
        "    input_data = [[loan_input, af_usa_loaded['term_in_months'].mean(), af_usa_loaded['lender_count'].mean()]]\n",
        "    input_scaled = scaler.transform(input_data)\n",
        "    input_pca = pca.transform(input_scaled)\n",
        "    input_cluster = kmeans_model.predict(input_pca)[0]\n",
        "\n",
        "    # Anbefalinger fra samme klynge\n",
        "    recommended_loans = af_usa_loaded[af_usa_loaded['cluster_kmeans'] == input_cluster].head(5)\n",
        "    return recommended_loans[['loan_amount', 'term_in_months', 'lender_count', 'sector', 'activity']]"
      ],
      "metadata": {
        "id": "2fN17XvXecQ2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eksempel på brug af funktionerne\n",
        "loan_description = \"purchase of equipment for business\"\n",
        "predicted_chance = recommend_chance_supervised(loan_description)\n",
        "similar_loans = find_similar_loans(5000)\n",
        "\n",
        "(predicted_chance, similar_loans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKe1PK2vrbjs",
        "outputId": "d985e256-3933-4771-e51e-46c02700159f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('High Chance',\n",
              "    loan_amount  term_in_months  lender_count       sector         activity\n",
              " 1       4000.0            26.0            93       Retail  Cosmetics Sales\n",
              " 3       5000.0            32.0           158  Agriculture          Farming\n",
              " 4       5450.0            32.0           164     Services         Services\n",
              " 6       5450.0            32.0           166       Retail           Retail\n",
              " 8       5000.0            24.0           150         Food       Restaurant)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}